"""
YOUTHY AI ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸

ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œ ì²­ë…„ì •ì±… ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
2025ë…„ 9ì›” ê¸°ì¤€ ì‹¤ì œ APIì™€ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥ API í˜¸ì¶œ
2. ì²­ë…„ì •ì±… í¬í„¸ ì›¹ í¬ë¡¤ë§  
3. ì„œìš¸ì‹œ ê³ ì‹œÂ·ê³µê³  RSS íŒŒì‹±
4. ë°ì´í„° ì •ê·œí™” ë° ì €ì¥
5. ì„ë² ë”© ìƒì„± ë° ì¸ë±ì‹±
"""

import asyncio
import logging
import argparse
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import json
import hashlib

import aiohttp
import asyncpg
from bs4 import BeautifulSoup
import pandas as pd
from sentence_transformers import SentenceTransformer

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class YouthyDataPipeline:
    """
    YOUTHY AI ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ ë©”ì¸ í´ë˜ìŠ¤
    
    ì‹¤ì œ ìš´ì˜ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
    ê° ë°ì´í„° ì†ŒìŠ¤ë³„ë¡œ ì „ìš© ìˆ˜ì§‘ê¸°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
    """
    
    def __init__(self):
        # ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥ API í‚¤ (ì‹¤ì œ ë°œê¸‰ë°›ì€ í‚¤)
        self.seoul_api_key = "75786159696b6a6839324d7a674776"
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ íŠ¹í™”)
        logger.info("ğŸ¤– AI ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.embedding_model = SentenceTransformer('BAAI/bge-m3')
        logger.info("âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´
        self.db_config = {
            'host': 'localhost',
            'port': 5432,
            'database': 'youthy_ai',
            'user': 'postgres',
            'password': 'password'
        }
        
        # ìˆ˜ì§‘ í†µê³„
        self.stats = {
            'total_processed': 0,
            'new_policies': 0,
            'updated_policies': 0,
            'errors': 0
        }

    async def connect_db(self) -> asyncpg.Connection:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        try:
            conn = await asyncpg.connect(**self.db_config)
            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
            return conn
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise

    async def collect_seoul_open_data(self) -> List[Dict[str, Any]]:
        """
        ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥ì—ì„œ ì²­ë…„ì •ì±… ë°ì´í„° ìˆ˜ì§‘
        
        ì‹¤ì œ API í˜¸ì¶œ:
        - ì²­ë…„ì •ì±… ê´€ë ¨ ë°ì´í„°ì…‹ë“¤ì„ ìˆœíšŒ
        - JSON í˜•íƒœë¡œ ì •ì±… ì •ë³´ ìˆ˜ì§‘
        - API í˜¸ì¶œ ì œí•œ ì¤€ìˆ˜
        """
        logger.info("ğŸ“¡ ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        policies = []
        
        # ì‹¤ì œ API ì—”ë“œí¬ì¸íŠ¸ë“¤ (2025ë…„ 9ì›” ê¸°ì¤€)
        api_endpoints = [
            {
                'name': 'ì„œìš¸ì‹œ ì²­ë…„ì •ì±…',
                'url': 'http://openapi.seoul.go.kr:8088/{}/json/youthPolicyInfo/1/100/',
                'description': 'ì„œìš¸ì‹œ ì²­ë…„ì •ì±… ì „ì²´ ëª©ë¡'
            },
            {
                'name': 'ì„œìš¸ì‹œ êµ¬ë³„ ì²­ë…„ì •ì±…',
                'url': 'http://openapi.seoul.go.kr:8088/{}/json/districtYouthPolicy/1/100/',
                'description': 'ìì¹˜êµ¬ë³„ ì²­ë…„ì •ì±…'
            },
            {
                'name': 'ì„œìš¸ì‹œ ì²­ë…„ì§€ì›ì‚¬ì—…',
                'url': 'http://openapi.seoul.go.kr:8088/{}/json/youthSupportProgram/1/100/',
                'description': 'ì²­ë…„ì§€ì›ì‚¬ì—… í˜„í™©'
            }
        ]
        
        async with aiohttp.ClientSession() as session:
            for endpoint in api_endpoints:
                try:
                    url = endpoint['url'].format(self.seoul_api_key)
                    logger.info(f"ğŸ“¥ {endpoint['name']} ìˆ˜ì§‘ ì¤‘...")
                    
                    async with session.get(url) as response:
                        if response.status == 200:
                            data = await response.json()
                            
                            # API ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼ ë°ì´í„° ì¶”ì¶œ
                            if 'row' in data:
                                for item in data['row']:
                                    policy = await self._normalize_seoul_api_data(item, endpoint['name'])
                                    if policy:
                                        policies.append(policy)
                                        
                            logger.info(f"âœ… {endpoint['name']}: {len(data.get('row', []))}ê°œ ìˆ˜ì§‘")
                            
                        else:
                            logger.warning(f"âš ï¸ {endpoint['name']} API í˜¸ì¶œ ì‹¤íŒ¨: {response.status}")
                            
                        # API í˜¸ì¶œ ì œí•œ ì¤€ìˆ˜ (1ì´ˆ ëŒ€ê¸°)
                        await asyncio.sleep(1)
                        
                except Exception as e:
                    logger.error(f"âŒ {endpoint['name']} ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                    self.stats['errors'] += 1
        
        logger.info(f"ğŸ“Š ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥ ìˆ˜ì§‘ ì™„ë£Œ: {len(policies)}ê°œ")
        return policies

    async def _normalize_seoul_api_data(self, raw_data: Dict, source_name: str) -> Optional[Dict[str, Any]]:
        """
        ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥ API ì‘ë‹µì„ ì •ê·œí™”ëœ ì •ì±… ë°ì´í„°ë¡œ ë³€í™˜
        
        ì‹¤ì œ API ì‘ë‹µ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ìš°ë¦¬ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜í•©ë‹ˆë‹¤.
        """
        try:
            # ì •ì±… ID ìƒì„± (ì¤‘ë³µ ë°©ì§€)
            policy_id = f"seoul_{hashlib.md5(f'{raw_data.get('POLICY_NM', '')}{raw_data.get('POLICY_URL', '')}'.encode()).hexdigest()[:8]}"
            
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            title = raw_data.get('POLICY_NM', '').strip()
            if not title:
                return None
                
            # ì§€ì—­ ì •ë³´ ì¶”ì¶œ
            region = self._extract_region(raw_data.get('TARGET_AREA', ''))
            
            # ì—°ë ¹ ì •ë³´ ì¶”ì¶œ
            eligibility = self._extract_eligibility(raw_data)
            
            # ì •ì±… ìœ í˜• ë¶„ë¥˜
            category = self._classify_policy_category(title, raw_data.get('POLICY_CONTENT', ''))
            
            # ìœ íš¨ê¸°ê°„ ì¶”ì¶œ
            valid_from, valid_to = self._extract_validity_period(raw_data)
            
            # í˜„ì¬ ìƒíƒœ ê²°ì •
            status = self._determine_policy_status(valid_from, valid_to)
            
            return {
                'id': policy_id,
                'title': title,
                'summary': raw_data.get('POLICY_SUMMARY', ''),
                'body_html': raw_data.get('POLICY_CONTENT', ''),
                'issuing_agency': raw_data.get('AGENCY_NM', 'ì„œìš¸íŠ¹ë³„ì‹œ'),
                'program_type': raw_data.get('PROGRAM_TYPE', 'ì²­ë…„ì •ì±…'),
                'region': region,
                'category': category,
                'eligibility': eligibility,
                'benefit': self._extract_benefit_info(raw_data),
                'apply_method': self._extract_apply_method(raw_data),
                'contact': self._extract_contact_info(raw_data),
                'source_url': raw_data.get('POLICY_URL', ''),
                'source_name': source_name,
                'source_doc_date': datetime.now().date(),
                'valid_from': valid_from,
                'valid_to': valid_to,
                'status': status
            }
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ì •ê·œí™” ì˜¤ë¥˜: {e}")
            return None

    def _extract_region(self, target_area: str) -> str:
        """ëŒ€ìƒ ì§€ì—­ ì¶”ì¶œ ë° ì •ê·œí™”"""
        if not target_area:
            return 'ì„œìš¸ì‹œ ì „ì²´'
            
        # êµ¬ ì´ë¦„ ì¶”ì¶œ
        districts = [
            'ê°•ë‚¨êµ¬', 'ê°•ë™êµ¬', 'ê°•ë¶êµ¬', 'ê°•ì„œêµ¬', 'ê´€ì•…êµ¬', 'ê´‘ì§„êµ¬', 'êµ¬ë¡œêµ¬', 'ê¸ˆì²œêµ¬',
            'ë…¸ì›êµ¬', 'ë„ë´‰êµ¬', 'ë™ëŒ€ë¬¸êµ¬', 'ë™ì‘êµ¬', 'ë§ˆí¬êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ì„œì´ˆêµ¬', 'ì„±ë™êµ¬',
            'ì„±ë¶êµ¬', 'ì†¡íŒŒêµ¬', 'ì–‘ì²œêµ¬', 'ì˜ë“±í¬êµ¬', 'ìš©ì‚°êµ¬', 'ì€í‰êµ¬', 'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ì¤‘ë‘êµ¬'
        ]
        
        for district in districts:
            if district in target_area:
                return district
                
        return 'ì„œìš¸ì‹œ ì „ì²´'

    def _extract_eligibility(self, raw_data: Dict) -> Dict[str, Any]:
        """ì‹ ì²­ ìê²© ì¡°ê±´ ì¶”ì¶œ"""
        eligibility = {}
        
        # ì—°ë ¹ ì¡°ê±´ ì¶”ì¶œ
        age_text = raw_data.get('AGE_LIMIT', '') + ' ' + raw_data.get('POLICY_CONTENT', '')
        age_range = self._parse_age_range(age_text)
        if age_range:
            eligibility['age'] = age_range
            
        # ê±°ì£¼ ì¡°ê±´
        region = self._extract_region(raw_data.get('TARGET_AREA', ''))
        if region != 'ì„œìš¸ì‹œ ì „ì²´':
            eligibility['residency'] = {'districts': [region]}
        else:
            eligibility['residency'] = {'type': 'seoul'}
            
        # ì†Œë“ ì¡°ê±´ (í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ)
        income_info = self._extract_income_condition(raw_data.get('POLICY_CONTENT', ''))
        if income_info:
            eligibility['income'] = income_info
            
        return eligibility

    def _parse_age_range(self, text: str) -> Optional[Dict[str, int]]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì—°ë ¹ ë²”ìœ„ ì¶”ì¶œ"""
        import re
        
        # ë‹¤ì–‘í•œ ì—°ë ¹ í‘œí˜„ íŒ¨í„´ ë§¤ì¹­
        patterns = [
            r'(\d+)ì„¸\s*ì´ìƒ\s*(\d+)ì„¸\s*ì´í•˜',
            r'(\d+)ì„¸\s*~\s*(\d+)ì„¸',
            r'ë§Œ\s*(\d+)ì„¸\s*ì´ìƒ\s*(\d+)ì„¸\s*ì´í•˜',
            r'(\d+)ì„¸\s*ë¶€í„°\s*(\d+)ì„¸\s*ê¹Œì§€'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return {'min': int(match.group(1)), 'max': int(match.group(2))}
                
        # ë‹¨ì¼ ì—°ë ¹ ì¡°ê±´
        single_patterns = [
            r'(\d+)ì„¸\s*ì´ìƒ',
            r'ë§Œ\s*(\d+)ì„¸\s*ì´ìƒ'
        ]
        
        for pattern in single_patterns:
            match = re.search(pattern, text)
            if match:
                return {'min': int(match.group(1))}
                
        return None

    def _classify_policy_category(self, title: str, content: str) -> List[str]:
        """ì •ì±… ì œëª©ê³¼ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        categories = []
        text = (title + ' ' + content).lower()
        
        category_keywords = {
            'ì·¨ì—…': ['ì·¨ì—…', 'ì¼ìë¦¬', 'êµ¬ì§', 'ì±„ìš©', 'ì¸í„´', 'ì§ì—…', 'ê³ ìš©', 'êµ¬ì¸', 'ë©´ì ‘', 'ì´ë ¥ì„œ'],
            'ì°½ì—…': ['ì°½ì—…', 'ìŠ¤íƒ€íŠ¸ì—…', 'ì‚¬ì—…', 'ê¸°ì—…', 'ì°½ì—…ì§€ì›', 'ì‚¬ì—…ì', 'ë²¤ì²˜', 'íˆ¬ì'],
            'ì§„ë¡œ': ['ì§„ë¡œ', 'ê²½ë ¥', 'ì§ì—…ìƒë‹´', 'ì§„ë¡œìƒë‹´', 'ì»¤ë¦¬ì–´', 'ì§ì—…íƒìƒ‰', 'ì§„ë¡œì„¤ê³„'],
            'ì£¼ê±°': ['ì›”ì„¸', 'ì „ì„¸', 'ì£¼ê±°', 'ì„ëŒ€ë£Œ', 'ë³´ì¦ê¸ˆ', 'ì£¼íƒ', 'ì„ëŒ€', 'ê±°ì£¼', 'ì£¼ê±°ë¹„'],
            'ê¸ˆìœµ': ['ëŒ€ì¶œ', 'ê¸ˆìœµ', 'ìê¸ˆ', 'ì§€ì›ê¸ˆ', 'ë³´ì¡°ê¸ˆ', 'ì ê¸ˆ', 'íˆ¬ì', 'ê¸ˆìœµì§€ì›'],
            'êµìœ¡': ['êµìœ¡', 'í•™ìŠµ', 'ê°•ì˜', 'ì—°ìˆ˜', 'êµìœ¡ë¹„', 'í•™ë¹„', 'ìˆ˜ê°•', 'êµìœ¡ê³¼ì •', 'ì—­ëŸ‰'],
            'ì •ì‹ ê±´ê°•': ['ì •ì‹ ê±´ê°•', 'ì‹¬ë¦¬', 'ìƒë‹´', 'ìš°ìš¸', 'ìŠ¤íŠ¸ë ˆìŠ¤', 'ì •ì‹ ', 'ë§ˆìŒ', 'ì¹˜ë£Œ'],
            'ì‹ ì²´ê±´ê°•': ['ì‹ ì²´ê±´ê°•', 'ê±´ê°•', 'ì˜ë£Œ', 'ê²€ì§„', 'ìš´ë™', 'ì²´ë ¥', 'í—¬ìŠ¤', 'ê±´ê°•ê´€ë¦¬'],
            'ìƒí™œì§€ì›': ['ìƒí™œì§€ì›', 'ë³µì§€', 'ìƒí™œë¹„', 'ê¸°ì´ˆ', 'ëŒë´„', 'ì¼ìƒ', 'í¸ì˜', 'ì§€ì›'],
            'ë¬¸í™”/ì˜ˆìˆ ': ['ë¬¸í™”', 'ì˜ˆìˆ ', 'ê³µì—°', 'ì „ì‹œ', 'ì²´í—˜', 'ì¶•ì œ', 'ì˜ˆìˆ í™œë™', 'ë¬¸í™”í™œë™']
        }
        
        for category, keywords in category_keywords.items():
            if any(keyword in text for keyword in keywords):
                categories.append(category)
                
        return categories if categories else ['ê¸°íƒ€']

    def _extract_income_condition(self, content: str) -> Optional[Dict[str, Any]]:
        """ì†Œë“ ì¡°ê±´ ì¶”ì¶œ"""
        import re
        
        # ì¤‘ìœ„ì†Œë“ ê¸°ì¤€ íŒ¨í„´
        patterns = [
            r'ì¤‘ìœ„ì†Œë“\s*(\d+)%\s*ì´í•˜',
            r'ê¸°ì¤€ì¤‘ìœ„ì†Œë“\s*(\d+)%',
            r'(\d+)%\s*ì´í•˜'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content)
            if match:
                return {'ami_max': int(match.group(1))}
                
        return None

    def _extract_validity_period(self, raw_data: Dict) -> tuple:
        """ìœ íš¨ê¸°ê°„ ì¶”ì¶œ"""
        # ê¸°ë³¸ê°’: í˜„ì¬ë…„ë„ ì „ì²´
        default_start = datetime(2025, 1, 1).date()
        default_end = datetime(2025, 12, 31).date()
        
        try:
            # APIì—ì„œ ì œê³µí•˜ëŠ” ê¸°ê°„ ì •ë³´ê°€ ìˆë‹¤ë©´ ì‚¬ìš©
            start_date = raw_data.get('APPLY_START_DATE')
            end_date = raw_data.get('APPLY_END_DATE')
            
            if start_date:
                valid_from = datetime.strptime(start_date, '%Y-%m-%d').date()
            else:
                valid_from = default_start
                
            if end_date:
                valid_to = datetime.strptime(end_date, '%Y-%m-%d').date()
            else:
                valid_to = default_end
                
            return valid_from, valid_to
            
        except:
            return default_start, default_end

    def _determine_policy_status(self, valid_from, valid_to) -> str:
        """ì •ì±… ìƒíƒœ ê²°ì •"""
        today = datetime.now().date()
        
        if valid_from > today:
            return 'upcoming'
        elif valid_to < today:
            return 'closed'
        else:
            return 'open'

    def _extract_benefit_info(self, raw_data: Dict) -> Dict[str, Any]:
        """ì§€ì› í˜œíƒ ì •ë³´ ì¶”ì¶œ"""
        content = raw_data.get('POLICY_CONTENT', '')
        
        # ê¸ˆì•¡ ì¶”ì¶œ
        import re
        amount_patterns = [
            r'(\d{1,3}(?:,\d{3})*)\s*ë§Œì›',
            r'(\d{1,3}(?:,\d{3})*)\s*ì›',
            r'ìµœëŒ€\s*(\d{1,3}(?:,\d{3})*)'
        ]
        
        amount = None
        for pattern in amount_patterns:
            match = re.search(pattern, content)
            if match:
                amount_str = match.group(1).replace(',', '')
                amount = int(amount_str)
                if 'ë§Œì›' in match.group(0):
                    amount *= 10000
                break
        
        return {
            'type': 'cash' if amount else 'support',
            'amount': amount,
            'description': raw_data.get('SUPPORT_CONTENT', '')
        }

    def _extract_apply_method(self, raw_data: Dict) -> Dict[str, Any]:
        """ì‹ ì²­ ë°©ë²• ì •ë³´ ì¶”ì¶œ"""
        return {
            'method': 'online' if raw_data.get('APPLY_URL') else 'offline',
            'url': raw_data.get('APPLY_URL', ''),
            'procedure': raw_data.get('APPLY_PROCEDURE', ''),
            'documents': raw_data.get('REQUIRED_DOCS', '').split(',') if raw_data.get('REQUIRED_DOCS') else []
        }

    def _extract_contact_info(self, raw_data: Dict) -> Dict[str, Any]:
        """ì—°ë½ì²˜ ì •ë³´ ì¶”ì¶œ"""
        return {
            'department': raw_data.get('CONTACT_DEPT', ''),
            'phone': raw_data.get('CONTACT_PHONE', ''),
            'email': raw_data.get('CONTACT_EMAIL', ''),
            'address': raw_data.get('CONTACT_ADDRESS', '')
        }

    async def collect_youth_portal_data(self) -> List[Dict[str, Any]]:
        """
        ì„œìš¸ ì²­ë…„ì •ì±… í¬í„¸ ì›¹ í¬ë¡¤ë§
        
        ì‹¤ì œ ì›¹ì‚¬ì´íŠ¸ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ìµœì‹  ì •ì±… ì •ë³´ ìˆ˜ì§‘:
        - ì •ì±… ê²Œì‹œíŒ í˜ì´ì§€ íŒŒì‹±
        - ê° ì •ì±… ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§
        - êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
        """
        logger.info("ğŸ•·ï¸ ì²­ë…„ì •ì±… í¬í„¸ í¬ë¡¤ë§ ì‹œì‘...")
        
        policies = []
        base_url = "https://youth.seoul.go.kr"
        
        async with aiohttp.ClientSession() as session:
            try:
                # ì •ì±… ëª©ë¡ í˜ì´ì§€ í¬ë¡¤ë§
                list_url = f"{base_url}/site/main/archive/policy"
                async with session.get(list_url) as response:
                    if response.status == 200:
                        html = await response.text()
                        soup = BeautifulSoup(html, 'html.parser')
                        
                        # ì •ì±… ë§í¬ ì¶”ì¶œ
                        policy_links = soup.find_all('a', href=True)
                        policy_urls = []
                        
                        for link in policy_links:
                            href = link.get('href')
                            if href and '/policy/' in href:
                                full_url = href if href.startswith('http') else base_url + href
                                policy_urls.append(full_url)
                        
                        # ê° ì •ì±… ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (ìµœëŒ€ 50ê°œ)
                        for url in policy_urls[:50]:
                            try:
                                policy = await self._crawl_policy_detail(session, url)
                                if policy:
                                    policies.append(policy)
                                    
                                # í¬ë¡¤ë§ ê°„ê²© (ì„œë²„ ë¶€í•˜ ë°©ì§€)
                                await asyncio.sleep(0.5)
                                
                            except Exception as e:
                                logger.warning(f"âš ï¸ ì •ì±… ìƒì„¸ í¬ë¡¤ë§ ì‹¤íŒ¨ {url}: {e}")
                                
            except Exception as e:
                logger.error(f"âŒ ì²­ë…„ì •ì±… í¬í„¸ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
                self.stats['errors'] += 1
        
        logger.info(f"ğŸ“Š ì²­ë…„ì •ì±… í¬í„¸ ìˆ˜ì§‘ ì™„ë£Œ: {len(policies)}ê°œ")
        return policies

    async def _crawl_policy_detail(self, session: aiohttp.ClientSession, url: str) -> Optional[Dict[str, Any]]:
        """ê°œë³„ ì •ì±… ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§"""
        try:
            async with session.get(url) as response:
                if response.status != 200:
                    return None
                    
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                # ì œëª© ì¶”ì¶œ
                title_elem = soup.find('h1') or soup.find('h2') or soup.find('.title')
                title = title_elem.get_text().strip() if title_elem else ''
                
                if not title:
                    return None
                
                # ì •ì±… ID ìƒì„±
                policy_id = f"youth_portal_{hashlib.md5(url.encode()).hexdigest()[:8]}"
                
                # ë‚´ìš© ì¶”ì¶œ
                content_elem = soup.find('.content') or soup.find('.policy-content') or soup.find('main')
                content = content_elem.get_text().strip() if content_elem else ''
                
                return {
                    'id': policy_id,
                    'title': title,
                    'summary': content[:200] + '...' if len(content) > 200 else content,
                    'body_html': str(content_elem) if content_elem else '',
                    'issuing_agency': 'ì„œìš¸íŠ¹ë³„ì‹œ',
                    'program_type': 'ì²­ë…„ì •ì±…',
                    'region': self._extract_region(content),
                    'category': self._classify_policy_category(title, content),
                    'eligibility': self._extract_eligibility_from_text(content),
                    'benefit': {'type': 'support', 'description': content[:500]},
                    'apply_method': {'method': 'online', 'url': url},
                    'contact': {'department': 'ì²­ë…„ì •ì±…ê³¼'},
                    'source_url': url,
                    'source_name': 'ì„œìš¸ ì²­ë…„ì •ì±… í¬í„¸',
                    'source_doc_date': datetime.now().date(),
                    'valid_from': datetime(2025, 1, 1).date(),
                    'valid_to': datetime(2025, 12, 31).date(),
                    'status': 'open'
                }
                
        except Exception as e:
            logger.error(f"âŒ ì •ì±… ìƒì„¸ í¬ë¡¤ë§ ì˜¤ë¥˜ {url}: {e}")
            return None

    def _extract_eligibility_from_text(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ì—ì„œ ìê²© ì¡°ê±´ ì¶”ì¶œ"""
        eligibility = {}
        
        # ì—°ë ¹ ì¡°ê±´
        age_range = self._parse_age_range(text)
        if age_range:
            eligibility['age'] = age_range
            
        # í•™ìƒ ì—¬ë¶€
        if any(keyword in text for keyword in ['ëŒ€í•™ìƒ', 'í•™ìƒ', 'ì¬í•™']):
            eligibility['student'] = True
            
        # ì†Œë“ ì¡°ê±´
        income_info = self._extract_income_condition(text)
        if income_info:
            eligibility['income'] = income_info
            
        return eligibility

    async def save_policies_to_db(self, policies: List[Dict[str, Any]]):
        """
        ì •ì±… ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        
        ì¤‘ë³µ ê²€ì‚¬ë¥¼ í†µí•´ ìƒˆë¡œìš´ ì •ì±…ë§Œ ì¶”ê°€í•˜ê³ ,
        ê¸°ì¡´ ì •ì±…ì´ ë³€ê²½ëœ ê²½ìš° ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        """
        logger.info("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹œì‘...")
        
        conn = await self.connect_db()
        
        try:
            for policy in policies:
                try:
                    # ê¸°ì¡´ ì •ì±… í™•ì¸
                    existing = await conn.fetchrow(
                        "SELECT id, version FROM policies WHERE id = $1",
                        policy['id']
                    )
                    
                    if existing:
                        # ê¸°ì¡´ ì •ì±… ì—…ë°ì´íŠ¸
                        await conn.execute("""
                            UPDATE policies SET
                                title = $2, summary = $3, body_html = $4,
                                issuing_agency = $5, program_type = $6,
                                region = $7, category = $8, eligibility = $9,
                                benefit = $10, apply_method = $11, contact = $12,
                                source_url = $13, source_name = $14,
                                valid_from = $15, valid_to = $16, status = $17,
                                version = $18, updated_at = NOW()
                            WHERE id = $1
                        """, 
                        policy['id'], policy['title'], policy['summary'], policy['body_html'],
                        policy['issuing_agency'], policy['program_type'],
                        policy['region'], policy['category'], json.dumps(policy['eligibility']),
                        json.dumps(policy['benefit']), json.dumps(policy['apply_method']), 
                        json.dumps(policy['contact']), policy['source_url'], policy['source_name'],
                        policy['valid_from'], policy['valid_to'], policy['status'],
                        existing['version'] + 1
                        )
                        
                        self.stats['updated_policies'] += 1
                        logger.info(f"ğŸ”„ ì •ì±… ì—…ë°ì´íŠ¸: {policy['title']}")
                        
                    else:
                        # ìƒˆ ì •ì±… ì¶”ê°€
                        await conn.execute("""
                            INSERT INTO policies (
                                id, title, summary, body_html, issuing_agency, program_type,
                                region, category, eligibility, benefit, apply_method, contact,
                                source_url, source_name, source_doc_date,
                                valid_from, valid_to, status
                            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18)
                        """, 
                        policy['id'], policy['title'], policy['summary'], policy['body_html'],
                        policy['issuing_agency'], policy['program_type'],
                        policy['region'], policy['category'], json.dumps(policy['eligibility']),
                        json.dumps(policy['benefit']), json.dumps(policy['apply_method']), 
                        json.dumps(policy['contact']), policy['source_url'], policy['source_name'],
                        policy['source_doc_date'], policy['valid_from'], policy['valid_to'], policy['status']
                        )
                        
                        self.stats['new_policies'] += 1
                        logger.info(f"âœ¨ ìƒˆ ì •ì±… ì¶”ê°€: {policy['title']}")
                    
                    # ì²­í¬ ìƒì„± ë° ì„ë² ë”©
                    await self._create_policy_chunks(conn, policy)
                    
                    self.stats['total_processed'] += 1
                    
                except Exception as e:
                    logger.error(f"âŒ ì •ì±… ì €ì¥ ì˜¤ë¥˜ {policy.get('title', 'Unknown')}: {e}")
                    self.stats['errors'] += 1
                    
        finally:
            await conn.close()
            
        logger.info(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ!")

    async def _create_policy_chunks(self, conn: asyncpg.Connection, policy: Dict[str, Any]):
        """
        ì •ì±…ì„ ê²€ìƒ‰ ê°€ëŠ¥í•œ ì²­í¬ë¡œ ë¶„í• í•˜ê³  ì„ë² ë”© ìƒì„±
        
        ê¸´ ì •ì±… ë¬¸ì„œë¥¼ ì‘ì€ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
        ê° ì²­í¬ì— ëŒ€í•´ ë²¡í„° ì„ë² ë”©ì„ ìƒì„±í•˜ì—¬ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì„ ì§€ì›í•©ë‹ˆë‹¤.
        """
        try:
            # ê¸°ì¡´ ì²­í¬ ì‚­ì œ
            await conn.execute("DELETE FROM policy_chunks WHERE policy_id = $1", policy['id'])
            
            # ì„¹ì…˜ë³„ë¡œ í…ìŠ¤íŠ¸ ë¶„í• 
            sections = {
                'ì •ì±…ê°œìš”': f"{policy['title']} {policy['summary']}",
                'ì‹ ì²­ìê²©': self._extract_section_text(policy['body_html'], ['ìê²©', 'ëŒ€ìƒ', 'ì¡°ê±´']),
                'ì§€ì›ë‚´ìš©': self._extract_section_text(policy['body_html'], ['ì§€ì›', 'í˜œíƒ', 'ë‚´ìš©']),
                'ì‹ ì²­ë°©ë²•': self._extract_section_text(policy['body_html'], ['ì‹ ì²­', 'ë°©ë²•', 'ì ˆì°¨']),
                'ë¬¸ì˜ì²˜': json.dumps(policy['contact'], ensure_ascii=False)
            }
            
            chunk_order = 0
            for section, text in sections.items():
                if text and text.strip():
                    # ì„ë² ë”© ìƒì„±
                    embedding = self.embedding_model.encode(text)
                    embedding_list = embedding.tolist()
                    
                    # ì²­í¬ ì €ì¥
                    await conn.execute("""
                        INSERT INTO policy_chunks (
                            policy_id, section, chunk_order, chunk_text, embedding
                        ) VALUES ($1, $2, $3, $4, $5)
                    """, policy['id'], section, chunk_order, text, embedding_list)
                    
                    chunk_order += 1
                    
        except Exception as e:
            logger.error(f"âŒ ì²­í¬ ìƒì„± ì˜¤ë¥˜ {policy['id']}: {e}")

    def _extract_section_text(self, html_content: str, keywords: List[str]) -> str:
        """HTMLì—ì„œ íŠ¹ì • ì„¹ì…˜ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if not html_content:
            return ''
            
        soup = BeautifulSoup(html_content, 'html.parser')
        text = soup.get_text()
        
        # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ë‹¨ ì°¾ê¸°
        sentences = text.split('.')
        relevant_sentences = []
        
        for sentence in sentences:
            if any(keyword in sentence for keyword in keywords):
                relevant_sentences.append(sentence.strip())
                
        return '. '.join(relevant_sentences) if relevant_sentences else text[:500]

    async def log_ingest_run(self, source_name: str, status: str, error_message: str = None):
        """ë°ì´í„° ìˆ˜ì§‘ ë¡œê·¸ ê¸°ë¡"""
        conn = await self.connect_db()
        
        try:
            await conn.execute("""
                INSERT INTO ingest_logs (
                    source_name, start_time, end_time, status,
                    records_processed, records_updated, records_created, error_message
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
            """, 
            source_name, datetime.now(), datetime.now(), status,
            self.stats['total_processed'], self.stats['updated_policies'], 
            self.stats['new_policies'], error_message
            )
        finally:
            await conn.close()

    async def run_full_pipeline(self):
        """
        ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì •ì±… ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
        ì‹¤ì œ ìš´ì˜ì—ì„œ ìŠ¤ì¼€ì¤„ëŸ¬ì— ì˜í•´ ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        logger.info("ğŸš€ YOUTHY AI ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ ì‹œì‘!")
        start_time = datetime.now()
        
        try:
            # 1. ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥ ìˆ˜ì§‘
            seoul_policies = await self.collect_seoul_open_data()
            
            # 2. ì²­ë…„ì •ì±… í¬í„¸ ìˆ˜ì§‘
            portal_policies = await self.collect_youth_portal_data()
            
            # 3. ëª¨ë“  ì •ì±… ë°ì´í„° í†µí•©
            all_policies = seoul_policies + portal_policies
            
            if all_policies:
                # 4. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
                await self.save_policies_to_db(all_policies)
                
                # 5. ë¡œê·¸ ê¸°ë¡
                await self.log_ingest_run("ì „ì²´ íŒŒì´í”„ë¼ì¸", "success")
                
                # 6. ê²°ê³¼ ë¦¬í¬íŠ¸
                end_time = datetime.now()
                duration = (end_time - start_time).total_seconds()
                
                logger.info("ğŸ‰ ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
                logger.info(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
                logger.info(f"   â€¢ ì´ ì²˜ë¦¬: {self.stats['total_processed']}ê°œ")
                logger.info(f"   â€¢ ì‹ ê·œ ì¶”ê°€: {self.stats['new_policies']}ê°œ")
                logger.info(f"   â€¢ ì—…ë°ì´íŠ¸: {self.stats['updated_policies']}ê°œ")
                logger.info(f"   â€¢ ì˜¤ë¥˜: {self.stats['errors']}ê°œ")
                logger.info(f"   â€¢ ì†Œìš”ì‹œê°„: {duration:.1f}ì´ˆ")
                
            else:
                logger.warning("âš ï¸ ìˆ˜ì§‘ëœ ì •ì±… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                await self.log_ingest_run("ì „ì²´ íŒŒì´í”„ë¼ì¸", "failed", "ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ")
                
        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            await self.log_ingest_run("ì „ì²´ íŒŒì´í”„ë¼ì¸", "failed", str(e))
            raise

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='YOUTHY AI ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸')
    parser.add_argument('--initial-load', action='store_true', help='ì´ˆê¸° ë°ì´í„° ë¡œë”©')
    parser.add_argument('--source', choices=['seoul', 'portal', 'all'], default='all', help='ìˆ˜ì§‘í•  ë°ì´í„° ì†ŒìŠ¤')
    
    args = parser.parse_args()
    
    pipeline = YouthyDataPipeline()
    
    if args.initial_load:
        logger.info("ğŸ”„ ì´ˆê¸° ë°ì´í„° ë¡œë”© ì‹œì‘...")
        
    await pipeline.run_full_pipeline()

if __name__ == "__main__":
    asyncio.run(main())
